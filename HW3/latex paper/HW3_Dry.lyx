#LyX 2.3 created this file. For more info see http://www.lyx.org/
\lyxformat 544
\begin_document
\begin_header
\save_transient_properties true
\origin unavailable
\textclass report
\begin_preamble
\usepackage{culmus}
\end_preamble
\use_default_options true
\maintain_unincluded_children false
\language american
\language_package default
\inputencoding auto
\fontencoding global
\font_roman "default" "default"
\font_sans "default" "default"
\font_typewriter "default" "default"
\font_math "auto" "auto"
\font_default_family default
\use_non_tex_fonts false
\font_sc false
\font_osf false
\font_sf_scale 100 100
\font_tt_scale 100 100
\use_microtype false
\use_dash_ligatures true
\graphics default
\default_output_format default
\output_sync 0
\bibtex_command default
\index_command default
\paperfontsize default
\spacing single
\use_hyperref false
\papersize default
\use_geometry true
\use_package amsmath 1
\use_package amssymb 1
\use_package cancel 1
\use_package esint 1
\use_package mathdots 1
\use_package mathtools 1
\use_package mhchem 1
\use_package stackrel 1
\use_package stmaryrd 1
\use_package undertilde 1
\cite_engine basic
\cite_engine_type default
\biblio_style plain
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\justification true
\use_refstyle 1
\use_minted 0
\index Index
\shortcut idx
\color #008000
\end_index
\leftmargin 1cm
\topmargin 0.5cm
\rightmargin 1cm
\bottommargin 0.5cm
\secnumdepth 3
\tocdepth 3
\paragraph_separation indent
\paragraph_indentation default
\is_math_indent 0
\math_numbering_side default
\quotes_style english
\dynamic_quotes 0
\papercolumns 1
\papersides 1
\paperpagestyle default
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Standard

\series bold
\bar under
Dry Part:
\end_layout

\begin_layout Standard

\series bold
Q1:
\end_layout

\begin_layout Standard
The statement is 
\series bold
True.
\end_layout

\begin_layout Standard
Let some node n in the ID3 Algorithm.
 Without the normalization we choose to split by some continues feature
 -f.
 After performing dynamic discretization we get that the highest IG we can
 get is by using feature f and some value 
\begin_inset Formula $t_{j}$
\end_inset

 .
\end_layout

\begin_layout Standard
Now let us consider the MinMax normalization.
 let 
\begin_inset Formula $x$
\end_inset

 be the value of the feature, the normalized value is 
\begin_inset Formula $x_{n}$
\end_inset

 :
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
x_{n}=\frac{x-x_{min}}{x_{max}-x_{min}}=\frac{x}{x_{max}-x_{min}}-\frac{x_{min}}{x_{max}-x_{min}}
\]

\end_inset


\end_layout

\begin_layout Standard
The normalization value is a linear function of the original value, and
 this is monotonically increasing function.
\end_layout

\begin_layout Standard
Thus performing the dynamic discretization and preform the splitting by
 every feature will be same as without the normalization (the values by
 itself aren't important, the important thing is the order- if 
\begin_inset Formula $x_{2}>x_{1}$
\end_inset

then 
\begin_inset Formula $x_{n_{2}}>x_{n_{1}}$
\end_inset

, so if the order of the examples haven't changed then the IG won't change-
 we will chose the same feature and relative place to divide the examples
 by that feature, and thus the same tree will be built and the accuracy
 will be the same.
\end_layout

\begin_layout Standard
__
\end_layout

\begin_layout Standard
______
\end_layout

\begin_layout Standard

\series bold
Question N2:
\end_layout

\begin_layout Standard

\bar under
General Explanation of the plots:
\end_layout

\begin_layout Standard
blue background - goal classifier 
\end_layout

\begin_layout Standard
green and red points- example nodes labeled 1 and 0 respectively.
\end_layout

\begin_layout Standard
x Markers - test examples we discussing.
\end_layout

\begin_layout Standard
red lines- goal classifier returns 0
\end_layout

\begin_layout Standard
blue lines- goal classifier returns 1
\end_layout

\begin_layout Standard

\series bold
(a)
\end_layout

\begin_layout Standard
\begin_inset Formula $D=\{<(0,1),1>,<(0,-1),0>\}$
\end_inset


\end_layout

\begin_layout Standard
classifier 
\begin_inset Formula $F_{true}=1\ if\ v_{2}>0$
\end_inset


\end_layout

\begin_layout Standard
\begin_inset Graphics
	filename pic_Q2_HW3/a.png

\end_inset


\end_layout

\begin_layout Standard
ID3: 
\begin_inset Formula $v_{1}$
\end_inset

 feature isn't informative and by using 
\begin_inset Formula $v_{2}$
\end_inset

 we reach the leaves.
 ID3 will check if 
\begin_inset Formula $v_{2}$
\end_inset

>0 (zero is the avg.
 of 
\begin_inset Formula $v_{2}$
\end_inset

) and we will find the goal classifier.
\end_layout

\begin_layout Standard
KNN:
\end_layout

\begin_layout Standard
for testing point 
\begin_inset Formula $x_{q}=(0,0)$
\end_inset

: 
\begin_inset Formula $d(x_{q},(0,1))=d(x_{q},(0,-1))$
\end_inset

 thus we choose the node with higher 
\begin_inset Formula $v_{2}$
\end_inset

 and returning its label, i.e.
 
\begin_inset Formula $KNN(x_{q})=1$
\end_inset

 and that is wrong.
 
\end_layout

\begin_layout Standard
We found that 
\begin_inset Formula $\nexists x_{q}:\ KNN(x_{q})\neq F_{true}$
\end_inset

 .
 
\end_layout

\begin_layout Standard

\series bold
Thus ID3 Right and KNN not always.
\end_layout

\begin_layout Standard
___
\end_layout

\begin_layout Standard

\series bold
(b)
\end_layout

\begin_layout Standard
\begin_inset Formula $D=\{<(1,-1),1>,<(-1,1),0>\}$
\end_inset


\end_layout

\begin_layout Standard
classifier: 
\begin_inset Formula $F_{true}=\begin{array}{c}
1\;v1\geq v2\\
0\;v1<v2
\end{array}$
\end_inset


\end_layout

\begin_layout Standard
\begin_inset Graphics
	filename pic_Q2_HW3/b.png

\end_inset


\end_layout

\begin_layout Standard
The ID3 will use only one feature cause after one division it riches a leaf
 e.g.
 taking 
\begin_inset Formula $v1>0\ or\ v2>0$
\end_inset

 and this is clearly bad.
 (see image)
\end_layout

\begin_layout Standard
KNN will be right in every situation.
 if 
\begin_inset Formula $x_{q}$
\end_inset

features are equal 
\begin_inset Formula $v_{1}=v_{2}$
\end_inset

 , the distances to both training nodes are equal and it will take the positive
 nodes 
\begin_inset Formula $<(1,-1),1>$
\end_inset

 because of higher 
\begin_inset Formula $v_{1}$
\end_inset

 which is consistent with the true classifier.
 Else 
\begin_inset Formula $x_{q}:v_{1}\neq v_{2}$
\end_inset

 it will classify right by computing the distances to the nearest example
 node.
\end_layout

\begin_layout Standard
Thus 
\series bold
KNN always Right and ID3 not always right
\end_layout

\begin_layout Standard
____
\end_layout

\begin_layout Standard

\series bold
(c) 
\end_layout

\begin_layout Standard
choose K=1
\end_layout

\begin_layout Standard
\begin_inset Formula $D=\{<(1,-1),1>,<(-1,1),0>\}$
\end_inset


\end_layout

\begin_layout Standard
classifier: 
\begin_inset Formula $F_{true}=\begin{array}{c}
1\;v1>v2\\
0\;v1\leq v2
\end{array}$
\end_inset


\end_layout

\begin_layout Standard
\begin_inset Graphics
	filename pic_Q2_HW3/c.png

\end_inset


\end_layout

\begin_layout Standard
The ID3 will use only one feature cause after one division it riches a leaf
 e.g.
 taking 
\begin_inset Formula $v1>0\ or\ v2>0$
\end_inset

 and this is clearly bad.
 (see image)
\end_layout

\begin_layout Standard
KNN will be wrong at points whose 
\begin_inset Formula $v_{1}=v_{2}$
\end_inset

: the distances to both training nodes are equal and it will take the positive
 nodes 
\begin_inset Formula $<(1,-1),1>$
\end_inset

 because of higher 
\begin_inset Formula $v_{1}$
\end_inset

 and return True (1).
\end_layout

\begin_layout Standard
However the true classifier will label it as False (0).
\end_layout

\begin_layout Standard
Thus 
\series bold
ID3 and KNN not always right .
\end_layout

\begin_layout Standard
__________
\end_layout

\begin_layout Standard

\series bold
(d)
\end_layout

\begin_layout Standard
K=1:
\end_layout

\begin_layout Standard
\begin_inset Formula $D=\{<(0,1),1>,<(0,-1),0>\}$
\end_inset


\end_layout

\begin_layout Standard
classifier 
\begin_inset Formula $F_{true}=1\ if\ v_{2}\geq0$
\end_inset


\end_layout

\begin_layout Standard
\begin_inset Graphics
	filename pic_Q2_HW3/d.png

\end_inset


\end_layout

\begin_layout Standard
ID3: 
\begin_inset Formula $v_{1}$
\end_inset

 feature isn't informative and by using 
\begin_inset Formula $v_{2}$
\end_inset

 we can get to the leaves.
 ID3 will check if 
\begin_inset Formula $v_{2}$
\end_inset

>0 and we will get the goal classifier.
\end_layout

\begin_layout Standard
KNN:
\end_layout

\begin_layout Standard
if 
\begin_inset Formula $x_{q}:v2=0$
\end_inset

, the distance to the examples are equal and the label will be taken from
 the higher 
\begin_inset Formula $v_{2}$
\end_inset

 example and return 1 (Right).
 
\end_layout

\begin_layout Standard
else (
\begin_inset Formula $v_{2}\neq0)$
\end_inset

 the KNN is working good.
 for 
\begin_inset Formula $v_{2}>0$
\end_inset

 the nearest example is (0,1) and the label is 1 and for 
\begin_inset Formula $v_{1}<0$
\end_inset

 the nearest example is (0,-1) and the label is 0, thus in both cases it
 is consistent with classifier).
\end_layout

\begin_layout Standard
Thus 
\series bold
KNN and ID3 are always right
\end_layout

\begin_layout Standard
—————-
\end_layout

\begin_layout Standard

\series bold
Question 3:
\end_layout

\begin_layout Standard

\series bold
(a)
\end_layout

\begin_layout Standard

\bar under
Majority classifier:
\end_layout

\begin_layout Standard
number of positive labels (y=1) is 5 and number of negative labels (y=0)
 is 5.
 There is no majority (tie), but as the question dictates we say the majority
 is y=1.
\end_layout

\begin_layout Standard
Checking the accuracy of the majority classifier on the example set:
\end_layout

\begin_layout Standard
\begin_inset Formula $C(x_{i})=1\ \forall x_{i}=1,2\ldots10$
\end_inset

.
 Because half of the examples were labeled as 1 and hale as 0, the classifier
 will be right half of the times.
\end_layout

\begin_layout Standard
\begin_inset Formula $accuracy=\frac{\#(right\ classified\ examples)}{\#examples}$
\end_inset

=0.5
\end_layout

\begin_layout Standard
_______________
\end_layout

\begin_layout Standard

\series bold
(b) 
\end_layout

\begin_layout Standard

\bar under
Running cross fold validation:
\end_layout

\begin_layout Standard

\bar under
First fold:
\end_layout

\begin_layout Standard
\begin_inset Formula $x_{training}=[1,2,3,4,5]$
\end_inset

 
\begin_inset Formula $y_{training}=[1,1,0,1,1]$
\end_inset

 
\end_layout

\begin_layout Standard
The majority classifier is 
\begin_inset Formula $C_{1}(x)\equiv1$
\end_inset


\end_layout

\begin_layout Standard
check over the testing fold:
\end_layout

\begin_layout Standard
\begin_inset Formula $x_{testing}=[6,7,8,9,10]$
\end_inset

 
\begin_inset Formula $y_{testing}=[0,0,1,0,0]$
\end_inset


\end_layout

\begin_layout Standard
The classifier over the testing points will return: 
\begin_inset Formula $y_{predict}=[1,1,1,1,1]$
\end_inset


\end_layout

\begin_layout Standard
The error is 
\begin_inset Formula $\epsilon_{1}=4/5$
\end_inset

 
\end_layout

\begin_layout Standard

\bar under
Second fold:
\end_layout

\begin_layout Standard
\begin_inset Formula $x_{training}=[6,7,8,9,10]$
\end_inset

 
\begin_inset Formula $y_{training}=[0,0,1,0,0]$
\end_inset

 
\end_layout

\begin_layout Standard
The majority classifier is 
\begin_inset Formula $C_{2}(x)\equiv0$
\end_inset


\end_layout

\begin_layout Standard
check over the testing fold:
\end_layout

\begin_layout Standard
\begin_inset Formula $x_{testing}=[1,2,3,4,5]$
\end_inset

 
\begin_inset Formula $y_{testing}=[1,1,0,1,1]$
\end_inset


\end_layout

\begin_layout Standard
The classifier over the testing points will return: 
\begin_inset Formula $y_{predict}=[0,0,0,0,0]$
\end_inset


\end_layout

\begin_layout Standard
The error is 
\begin_inset Formula $\epsilon_{2}=4/5$
\end_inset

 
\end_layout

\begin_layout Standard

\series bold
Conclusion:
\end_layout

\begin_layout Standard
The average error is 
\begin_inset Formula $\epsilon_{avg}=\frac{1}{N}\sum\epsilon_{i}=4/5$
\end_inset

 
\end_layout

\begin_layout Standard

\series bold
\bar under
The accuracy of the algorithm 
\begin_inset Formula $accuracy=1-error=1/5$
\end_inset


\end_layout

\end_body
\end_document
