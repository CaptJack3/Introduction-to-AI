#LyX 2.3 created this file. For more info see http://www.lyx.org/
\lyxformat 544
\begin_document
\begin_header
\save_transient_properties true
\origin unavailable
\textclass report
\begin_preamble
\usepackage{culmus}
\end_preamble
\use_default_options true
\maintain_unincluded_children false
\language american
\language_package default
\inputencoding auto
\fontencoding global
\font_roman "default" "default"
\font_sans "default" "default"
\font_typewriter "default" "default"
\font_math "auto" "auto"
\font_default_family default
\use_non_tex_fonts false
\font_sc false
\font_osf false
\font_sf_scale 100 100
\font_tt_scale 100 100
\use_microtype false
\use_dash_ligatures true
\graphics default
\default_output_format default
\output_sync 0
\bibtex_command default
\index_command default
\paperfontsize default
\spacing single
\use_hyperref false
\papersize default
\use_geometry false
\use_package amsmath 1
\use_package amssymb 1
\use_package cancel 1
\use_package esint 1
\use_package mathdots 1
\use_package mathtools 1
\use_package mhchem 1
\use_package stackrel 1
\use_package stmaryrd 1
\use_package undertilde 1
\cite_engine basic
\cite_engine_type default
\biblio_style plain
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\justification true
\use_refstyle 1
\use_minted 0
\index Index
\shortcut idx
\color #008000
\end_index
\secnumdepth 3
\tocdepth 3
\paragraph_separation indent
\paragraph_indentation default
\is_math_indent 0
\math_numbering_side default
\quotes_style english
\dynamic_quotes 0
\papercolumns 1
\papersides 1
\paperpagestyle default
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Chapter*
Theorterical Part:
\end_layout

\begin_layout Section*
Question 1:
\end_layout

\begin_layout Standard

\bar under
Pros:
\end_layout

\begin_layout Itemize
Very easy to calculate (computational good)
\end_layout

\begin_layout Itemize
It's good indication for the first part of the game- when you have to stop
 the opponent from completing a mill.
\end_layout

\begin_layout Standard

\bar under
Cons:
\end_layout

\begin_layout Itemize
This heuristic doesn’t give a very good indication of the position evaluation:
\end_layout

\begin_deeper
\begin_layout Itemize
It's don't take into account the number of soldiers each player has.
\end_layout

\begin_layout Itemize
It's don't take into account the fact that the mobility is important in
 this game- a player which can't perform a move is losing
\end_layout

\end_deeper
\begin_layout Itemize

\series bold
Jacob TODO:copy here an examples and explain
\end_layout

\begin_layout Section*
Question 2
\end_layout

\begin_layout Standard
We will define the next heuristic:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
h(s)=Eval(White)-Eval(Black)
\]

\end_inset


\end_layout

\begin_layout Standard
if 
\begin_inset Formula $h(s)>0$
\end_inset

 white is better, else black is better.
\end_layout

\begin_layout Standard
We will define the evaluation fuction of each player by a weigheted sum:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
Eval(Player)=\sum_{i=1}c_{i}R_{i}
\]

\end_inset


\end_layout

\begin_layout Standard
R1= Number of closed mills: +1 If a mill was closed in the last move by
 the player 
\end_layout

\begin_layout Standard
R2= Number of mills
\end_layout

\begin_layout Standard
R3 = Number of blocked opponent pieces- pieces which don’t have an empty
 adjacent point
\end_layout

\begin_layout Standard
R4= Number of pieces 
\end_layout

\begin_layout Standard
R5= Number of 2-piece configuration (2 mans and one empty in a line) 
\end_layout

\begin_layout Standard
R6= Number of 3-piece configurations (A 3-piece configuration is one to
 which a piece can be added in which one of two ways to close a mills)
\end_layout

\begin_layout Standard

\series bold
Jacob TODO: rewriting the next paragraph (currently it's just copied from
 web)
\end_layout

\begin_layout Standard
R7= Double morris: Difference between number of yours and yours opponent’s
 double morrises (A double morris is one in which two morrises share a common
 piece)
\end_layout

\begin_layout Standard
R8=Winning configuration: 1 if the state is winning for the player, -1 if
 losing, 0 otherwise For the particular contest settings (elimination with
 the player having more pieces winning if neither side could force a win
 so there was a strong aversion to sacrificing material) and bot settings
 (depth limited to 8 and branching factor limited to 20; at each step, top
 20 moves sorted by the evaluation function were selected), I found the
 following feature combinations to work well (‘(1)’ represents the first
 feature: Closed Morris and so on) 
\begin_inset Newline newline
\end_inset


\end_layout

\begin_layout Standard
The motivation of using that heuristic is from a peper : 
\begin_inset Quotes eld
\end_inset

Nine Men’s Morris: Evaluation Functions
\begin_inset Quotes erd
\end_inset

 by: Simona-Alexandra PETCU, Stefan HOLBAN
\end_layout

\begin_layout Standard

\series bold
Jacob TODO: explain about coeeficients.
 Explain that for diffrent part of the game we use diffrent
\series default
 
\begin_inset Formula $c_{i}$
\end_inset


\end_layout

\begin_layout Standard

\series bold
In practice we don't have to use that complex heuristic, we can choose only
 4 parameters between the 8 described above....
\end_layout

\begin_layout Section*
Question 3
\end_layout

\begin_layout Description
a) 
\end_layout

\begin_layout Standard
The advantage of Alpha-beta pruning algorithm is that it 
\series bold
decrease the number of nodes that evaluated
\series default
 by an Minimax algorithm, although the selected move will be the same as
 in the regular minimax algorithm.By using the pruning, branches of the search
 tree can be eliminated, and 
\series bold
a deeper search can be performed
\series default
.
\begin_inset Newline newline
\end_inset

This advantage achieved by avoiding seaching subtrees of moves which won't
 be selected.
\begin_inset Newline newline
\end_inset

Algorithm Explanation
\begin_inset Foot
status open

\begin_layout Plain Layout
Based on: 
\begin_inset Quotes eld
\end_inset

Alpha-Beta Pruning: Algorithm and Analysis
\begin_inset Quotes erd
\end_inset

 by Tsan-sheng Hsu
\end_layout

\end_inset

:
\end_layout

\begin_layout Standard
for simplicity assuming a max node (Alpha cut off):
\end_layout

\begin_layout Description
\begin_inset Graphics
	filename Pics/3_a_1.png

\end_inset


\end_layout

\begin_layout Itemize
Assume you have finished exploring the branch at 1 and obtained the best
 value from it as 
\begin_inset Formula $bound$
\end_inset

.
\end_layout

\begin_layout Itemize
You now search the branch at 2 by first searching the branch at 2.1.
\end_layout

\begin_layout Itemize
Assume branch at 2.1 returns a value that is 
\begin_inset Formula $≤bound$
\end_inset

.
 
\end_layout

\begin_layout Itemize
Then no need to evaluate the branch at 2.2 and all later branches of 2, if
 any, at all.
 
\end_layout

\begin_layout Itemize
The best possible value for the branch at 2 must be 
\begin_inset Formula $≤bound$
\end_inset

.
 
\end_layout

\begin_layout Itemize
Hence we should take value returned from the branch at 1 as the best possible
 solution.
\end_layout

\begin_layout Description
b) (from Lecture No.5 slide 35) 
\begin_inset Newline newline
\end_inset

Optimal pruning happens when the extreme (min./max) value of every node is
 found first: 
\begin_inset Newline newline
\end_inset

In max nodes the highest minimax value is found in the first child
\begin_inset Newline newline
\end_inset

In min nodes the lowest minimax value is found in the first child 
\end_layout

\begin_layout Description
c)
\end_layout

\begin_layout Standard
No leaf will be pruned by alpha-beta :
\end_layout

\begin_layout Description
\begin_inset Graphics
	filename report_Images/image3_0.png
	scale 60

\end_inset


\begin_inset Newline newline
\end_inset


\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Section*
Question 4
\end_layout

\begin_layout Standard
Alpha beta pruning with some heuristic gave us exactly the same result (move)
 as minimax (with less calculations)
\end_layout

\begin_layout Standard
minimax algorithm with limited resources is as good as it's heuristic....
\end_layout

\begin_layout Standard
Minimax strategy is inefficient, since it discourages taking any risks,
 no matter how high the reward may be- It's takes the safe routes.
\begin_inset Newline newline
\end_inset


\end_layout

\begin_layout Section*
Question 5
\end_layout

\begin_layout Labeling
\labelwidthstring 00.00.0000
a) 
\end_layout

\begin_layout Labeling
\labelwidthstring 00.00.0000
b) 
\end_layout

\begin_layout Labeling
\labelwidthstring 00.00.0000
c)
\end_layout

\begin_layout Standard
TODO
\begin_inset Newline newline
\end_inset


\end_layout

\begin_layout Section*
Question 6
\end_layout

\begin_layout Standard
A student implemts an alpha-beta algorithm and in a game against the software
 she noticed that the computer didn't take a winning move (in the next step)
 and chose another step.
\end_layout

\begin_layout Standard
a.
 such situation possible because the heuristic mislead us-the wining move
 had lower heuristic value than the move actually performed.
 Probably, the used heuristic doesn't evaluate if the position end of the
 game.
 
\end_layout

\begin_layout Standard
b.
 The Change that we can perform is that if the alpha-beta algorithm gets
 a state that is winning for the Agent than it return that move.
\end_layout

\begin_layout Standard
In the picture below we can see the regular alpha-beta.
 
\end_layout

\begin_layout Standard
G(state) has to return an tuple ({T,F},{T,F}) - the first boolean value
 is True if the state is endgame and the second is True if it's the end
 of the game and Agent won.
\end_layout

\begin_layout Standard
If G(state) is (True,True) need to return the state with 
\begin_inset Formula $-\infty$
\end_inset

 or 
\begin_inset Formula $\infty$
\end_inset

 depenting if that a min agent or max agent respectively.
\end_layout

\begin_layout Standard
And the same for (True,False) return 
\begin_inset Formula $\pm\infty$
\end_inset

 depends on the agent type.
\end_layout

\begin_layout Standard
That way we can guarantee that the winning move is always will be returned.
\end_layout

\begin_layout Standard
\begin_inset Graphics
	filename Pics/6_b.png

\end_inset


\end_layout

\begin_layout Section*
Question 7
\end_layout

\begin_layout Standard
\begin_inset Graphics
	filename report_Images/7_0.png
	scale 60

\end_inset


\begin_inset Newline newline
\end_inset


\end_layout

\begin_layout Labeling
\labelwidthstring 00.00.0000
a) The expectimax of a chance node is calculated by a weighted sum of the
 utility and the probability to get it.
\begin_inset Newline newline
\end_inset


\begin_inset Formula $U(B)=0.3\cdot5+0.7\cdot1=2.2$
\end_inset


\begin_inset Newline newline
\end_inset


\begin_inset Formula $U(C)=0.4\cdot2+0.2\cdot3+0.4\cdot9=5$
\end_inset


\begin_inset Newline newline
\end_inset


\begin_inset Formula $U(D)=0.1\cdot4+0.9\cdot7=6.7$
\end_inset


\end_layout

\begin_layout Labeling
\labelwidthstring 00.00.0000
b) The max operator takes the path with the best value at the chance node:
\begin_inset Newline newline
\end_inset


\begin_inset Formula $U(A)=U(argmax(U(i))=U(D)=6.7$
\end_inset


\begin_inset Newline newline
\end_inset

 
\series bold
Thus action D
\end_layout

\begin_layout Labeling
\labelwidthstring 00.00.0000
c) NO we can't perform an alpha-beta pruning in an expectimax nodes because
 we can't calculate the expectimax value until we haven't exposed all the
 nodes.
\begin_inset Newline newline
\end_inset

We can perform a pruning if we got a higher and a lower bound of the leaves.
\begin_inset Newline newline
\end_inset

The regular Expectimax is calculated by 
\begin_inset Formula $Expectimax(state,action)=\sum_{i\in succ(state,action)}p_{i}u_{i}$
\end_inset

 where p,u are the probability and utility.
\begin_inset Newline newline
\end_inset

If we got a upper and lower bound of the utility 
\begin_inset Formula $(u_{min},u_{max})$
\end_inset

 we can predict the bounds of Expectimax node after revealing one possible
 successor:
\begin_inset Formula 
\[
Expectimax(state,action)\in[p_{1}\cdot u_{1}+(1-p_{1})\cdot u_{min},p_{1}\cdot u_{1}+(1-p_{1})\cdot u_{max}]
\]

\end_inset


\begin_inset Newline newline
\end_inset

But if not given an upper and lower bound, we can't prune for example:
\end_layout

\begin_layout Labeling
\labelwidthstring 00.00.0000
\begin_inset Graphics
	filename Pics/7_c.png

\end_inset


\end_layout

\begin_layout Standard
Assume the first action was been evaluated and the Expectimin returned 2.2
 .
 Now we need to evaluate the next action (a2).
\end_layout

\begin_layout Standard
The first successor looks promessing with high probability and value we
 already get 2.4 on our a2 chance node and seems that we don't need to check
 the next leaves...
\end_layout

\begin_layout Standard
However what if the value in D 
\backslash
 is negative and equals to -2? Than the result of the Expectimin operator
 on the second action equals 2 (smaller then a1 action)
\end_layout

\begin_layout Standard
That's why naive approach won't work.
\end_layout

\begin_layout Standard
(if we had some bound on the leaves e.g.
 positive value utility, we could say in the above example that after checking
 one leaf at the a2 action we coul'd guarantee that action a1 is better).
 
\end_layout

\begin_layout Section*
Question 8
\end_layout

\begin_layout Standard
TODO
\end_layout

\begin_layout Section*
Question 9
\end_layout

\begin_layout Standard

\series bold
\begin_inset Formula $\boldsymbol{d_{2}=\mathcal{O}(2\cdot d_{1}})$
\end_inset

 
\end_layout

\begin_layout Standard
The time complexity of minimax is 
\begin_inset Formula $O(b^{d})$
\end_inset

 i.e.
 function of the number ot leaves in the deepest searching layer.
\end_layout

\begin_layout Standard
If we get the rival_move we don't need to expand the whole opponent possible
 moves,just need to run this procedure.
 
\end_layout

\begin_layout Standard
Thus the tree size multiply by 
\begin_inset Formula $b$
\end_inset

 every two layers of actions (our node increase it by factor of 
\begin_inset Formula $b$
\end_inset

 and opponent move leaves it the same size).
\end_layout

\begin_layout Standard
\begin_inset Formula $O(b^{d_{1}})=O(b^{d_{2}/2})$
\end_inset

 i.e.
 
\begin_inset Formula $d_{2}=2\cdot d_{1}$
\end_inset

 (This is by asymptotic analysis)
\end_layout

\begin_layout Standard
b.
\end_layout

\begin_layout Standard
Q:Given state s what is the ratio between the value of the minimax with
 use of the procedure and the value of the minimax without of the procedure
 when both limitted to depth 
\begin_inset Formula $d$
\end_inset

 ?
\end_layout

\begin_layout Standard
The minimax value is the highest value that the player can be sure to get
 without knowing the actions of the opponent-It is the lowest value the
 rival can force the player to receive.
\end_layout

\begin_layout Standard
\begin_inset Formula $v_{i}=max(min(v_{i}))$
\end_inset


\end_layout

\begin_layout Standard
Minimax strategy assumes a perfect opponent,i.e.
 choosing the worst scenerio for our agent , but the rival don't neccesserely
 choose the action with the lowest utility (not the min)
\begin_inset Newline newline
\end_inset


\series bold
Thus minimax value without using rival_move procedure < minimax with using
 rival_move procedure.
\end_layout

\begin_layout Section*
Question 10
\end_layout

\begin_layout Standard
Given: maximiziation problem with search space of size 
\begin_inset Formula $10^{12}$
\end_inset


\end_layout

\begin_layout Standard
Solving with random-restart hill climbing.
\end_layout

\begin_layout Standard
Runing the algorithm 
\begin_inset Formula $10^{3}$
\end_inset

 times
\end_layout

\begin_layout Standard
a.
\end_layout

\begin_layout Standard
The student isn't necceseserly right to report that the optimum is at 5.8.
\end_layout

\begin_layout Standard
The reason is that he has been using a randomized algorithm and 
\begin_inset Formula $10^{3}$
\end_inset

 runs are low with respect to the state space size 
\begin_inset Formula $10^{12}$
\end_inset

 , thus 
\series bold
his result isn't statistical significant
\series default
.
\end_layout

\begin_layout Standard
b.
 If we had to varify the student's result we would use a 
\series bold
simulated annealing algorithm
\series default
.
 
\end_layout

\begin_layout Standard
The problem of SAHC algorithms is that they try to maximize the state and
 never makes 
\begin_inset Quotes eld
\end_inset

down-hill moves
\begin_inset Quotes erd
\end_inset

 toward states with lower value.
 
\end_layout

\begin_layout Standard
In contrast, 
\series bold
simulated annealing allows moving to states with lower value
\series default
.
\end_layout

\begin_layout Standard
c.
\end_layout

\begin_layout Standard
Add image and few word of explanation.
\end_layout

\begin_layout Chapter*
Wet Part:
\end_layout

\end_body
\end_document
